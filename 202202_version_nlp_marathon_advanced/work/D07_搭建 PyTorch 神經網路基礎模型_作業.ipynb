{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：了解 nn.Module的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印出 model底下所有 parameters 的 name 以及對應的 shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa: conv1.weight bbb: torch.Size([64, 3, 7, 7])\n",
      "aaa: bn1.weight bbb: torch.Size([64])\n",
      "aaa: bn1.bias bbb: torch.Size([64])\n",
      "aaa: layer1.0.conv1.weight bbb: torch.Size([64, 64, 3, 3])\n",
      "aaa: layer1.0.bn1.weight bbb: torch.Size([64])\n",
      "aaa: layer1.0.bn1.bias bbb: torch.Size([64])\n",
      "aaa: layer1.0.conv2.weight bbb: torch.Size([64, 64, 3, 3])\n",
      "aaa: layer1.0.bn2.weight bbb: torch.Size([64])\n",
      "aaa: layer1.0.bn2.bias bbb: torch.Size([64])\n",
      "aaa: layer1.1.conv1.weight bbb: torch.Size([64, 64, 3, 3])\n",
      "aaa: layer1.1.bn1.weight bbb: torch.Size([64])\n",
      "aaa: layer1.1.bn1.bias bbb: torch.Size([64])\n",
      "aaa: layer1.1.conv2.weight bbb: torch.Size([64, 64, 3, 3])\n",
      "aaa: layer1.1.bn2.weight bbb: torch.Size([64])\n",
      "aaa: layer1.1.bn2.bias bbb: torch.Size([64])\n",
      "aaa: layer2.0.conv1.weight bbb: torch.Size([128, 64, 3, 3])\n",
      "aaa: layer2.0.bn1.weight bbb: torch.Size([128])\n",
      "aaa: layer2.0.bn1.bias bbb: torch.Size([128])\n",
      "aaa: layer2.0.conv2.weight bbb: torch.Size([128, 128, 3, 3])\n",
      "aaa: layer2.0.bn2.weight bbb: torch.Size([128])\n",
      "aaa: layer2.0.bn2.bias bbb: torch.Size([128])\n",
      "aaa: layer2.0.downsample.0.weight bbb: torch.Size([128, 64, 1, 1])\n",
      "aaa: layer2.0.downsample.1.weight bbb: torch.Size([128])\n",
      "aaa: layer2.0.downsample.1.bias bbb: torch.Size([128])\n",
      "aaa: layer2.1.conv1.weight bbb: torch.Size([128, 128, 3, 3])\n",
      "aaa: layer2.1.bn1.weight bbb: torch.Size([128])\n",
      "aaa: layer2.1.bn1.bias bbb: torch.Size([128])\n",
      "aaa: layer2.1.conv2.weight bbb: torch.Size([128, 128, 3, 3])\n",
      "aaa: layer2.1.bn2.weight bbb: torch.Size([128])\n",
      "aaa: layer2.1.bn2.bias bbb: torch.Size([128])\n",
      "aaa: layer3.0.conv1.weight bbb: torch.Size([256, 128, 3, 3])\n",
      "aaa: layer3.0.bn1.weight bbb: torch.Size([256])\n",
      "aaa: layer3.0.bn1.bias bbb: torch.Size([256])\n",
      "aaa: layer3.0.conv2.weight bbb: torch.Size([256, 256, 3, 3])\n",
      "aaa: layer3.0.bn2.weight bbb: torch.Size([256])\n",
      "aaa: layer3.0.bn2.bias bbb: torch.Size([256])\n",
      "aaa: layer3.0.downsample.0.weight bbb: torch.Size([256, 128, 1, 1])\n",
      "aaa: layer3.0.downsample.1.weight bbb: torch.Size([256])\n",
      "aaa: layer3.0.downsample.1.bias bbb: torch.Size([256])\n",
      "aaa: layer3.1.conv1.weight bbb: torch.Size([256, 256, 3, 3])\n",
      "aaa: layer3.1.bn1.weight bbb: torch.Size([256])\n",
      "aaa: layer3.1.bn1.bias bbb: torch.Size([256])\n",
      "aaa: layer3.1.conv2.weight bbb: torch.Size([256, 256, 3, 3])\n",
      "aaa: layer3.1.bn2.weight bbb: torch.Size([256])\n",
      "aaa: layer3.1.bn2.bias bbb: torch.Size([256])\n",
      "aaa: layer4.0.conv1.weight bbb: torch.Size([512, 256, 3, 3])\n",
      "aaa: layer4.0.bn1.weight bbb: torch.Size([512])\n",
      "aaa: layer4.0.bn1.bias bbb: torch.Size([512])\n",
      "aaa: layer4.0.conv2.weight bbb: torch.Size([512, 512, 3, 3])\n",
      "aaa: layer4.0.bn2.weight bbb: torch.Size([512])\n",
      "aaa: layer4.0.bn2.bias bbb: torch.Size([512])\n",
      "aaa: layer4.0.downsample.0.weight bbb: torch.Size([512, 256, 1, 1])\n",
      "aaa: layer4.0.downsample.1.weight bbb: torch.Size([512])\n",
      "aaa: layer4.0.downsample.1.bias bbb: torch.Size([512])\n",
      "aaa: layer4.1.conv1.weight bbb: torch.Size([512, 512, 3, 3])\n",
      "aaa: layer4.1.bn1.weight bbb: torch.Size([512])\n",
      "aaa: layer4.1.bn1.bias bbb: torch.Size([512])\n",
      "aaa: layer4.1.conv2.weight bbb: torch.Size([512, 512, 3, 3])\n",
      "aaa: layer4.1.bn2.weight bbb: torch.Size([512])\n",
      "aaa: layer4.1.bn2.bias bbb: torch.Size([512])\n",
      "aaa: fc.weight bbb: torch.Size([1000, 512])\n",
      "aaa: fc.bias bbb: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print('aaa:',name, 'bbb:',param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 為了使 forward propagation 加速 並降低 memory 使用量，請將所有 parameters 的requires_grad 關閉，關閉之後執行  forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5852,  1.0942, -0.8445,  ..., -0.5095, -0.0897,  2.0410],\n",
       "          [ 0.0598,  0.5741,  1.3847,  ...,  0.7231,  1.0707, -0.1507],\n",
       "          [ 1.7219,  0.7560,  0.2560,  ..., -1.2163, -0.0154, -0.7877],\n",
       "          ...,\n",
       "          [-0.6013,  0.1469, -0.4294,  ..., -0.2511, -0.6213,  0.4176],\n",
       "          [-0.7369,  0.8902,  0.0079,  ..., -1.2185, -0.7383,  0.3169],\n",
       "          [ 0.2427, -1.5843, -1.3168,  ...,  0.1003,  1.0662,  0.2393]],\n",
       "\n",
       "         [[-0.8259, -0.7201,  0.0575,  ..., -1.4817,  1.3714, -0.2648],\n",
       "          [ 1.7483, -0.0338,  0.5948,  ..., -0.0932, -0.3720, -0.3951],\n",
       "          [-0.2381,  0.4801, -0.2078,  ...,  1.3701, -0.8560, -1.2664],\n",
       "          ...,\n",
       "          [-1.1189,  0.2391,  0.7367,  ...,  0.3612,  0.1360,  0.3627],\n",
       "          [ 0.5191, -0.9273,  1.5703,  ..., -0.2617, -0.7294,  0.8638],\n",
       "          [ 0.5738, -0.3648,  0.1828,  ..., -1.1349,  0.6002, -0.0592]],\n",
       "\n",
       "         [[-0.1387, -0.9102,  0.4443,  ..., -0.8908,  0.5625, -0.5389],\n",
       "          [-0.7360,  0.4541, -0.1928,  ..., -0.1651, -1.0217,  1.1659],\n",
       "          [-0.0779,  0.1020,  1.1617,  ...,  0.2152, -1.1814,  0.5671],\n",
       "          ...,\n",
       "          [-0.7931, -1.4034,  0.1623,  ...,  0.1806, -0.8827, -0.9489],\n",
       "          [ 1.3382,  0.6188, -0.9756,  ...,  0.1826, -0.0244, -0.7574],\n",
       "          [-0.6488,  0.5085,  0.1275,  ..., -0.1043, -0.6413,  0.7558]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = torch.randn(1, 3, 128, 128)\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "output = model(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：依照指令，以較簡潔的方式搭建出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input_shape = torch.Size([10, 12])\n",
    "* 先經過一層 nn.Linear(12, 10)\n",
    "* 經過10層 nn.Linear(10, 10)\n",
    "* 最後經過 nn.Linear(10, 3) 輸出\n",
    "* 每一個 nn.Linear過完後要先經過 nn.BatchNorm1d 才能到下一層，輸出層不用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(10,12)\n",
    "## 示範\n",
    "Linear = nn.Linear(12,10)\n",
    "BN = nn.BatchNorm1d(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.sequential = nn.Sequential(nn.Linear(12,10), nn.BatchNorm1d(10))\n",
    "        self.repeat_linear = nn.ModuleList([nn.Sequential(nn.Linear(10,10), nn.BatchNorm1d(10)) for _ in range(10)])\n",
    "        self.output = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        for module in self.repeat_linear:\n",
    "            x = module(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (sequential): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (repeat_linear): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(10,12)\n",
    "outupt = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6768, -0.0901, -0.0031],\n",
       "        [ 0.4180, -0.4599,  1.8801],\n",
       "        [-0.1755, -0.1612, -0.0391],\n",
       "        [-0.0480,  0.0881, -0.6903],\n",
       "        [-1.3550,  0.7311, -1.3749],\n",
       "        [ 0.2309, -0.4470, -0.0557],\n",
       "        [-0.2988, -0.1650, -0.1030],\n",
       "        [-0.5010, -0.6347, -0.5067],\n",
       "        [ 0.6583, -0.6786,  0.5469],\n",
       "        [ 0.3372, -0.7615,  0.8639]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
