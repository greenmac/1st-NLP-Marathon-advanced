{"cells":[{"cell_type":"markdown","metadata":{"id":"QUAjcc2h3Ggm"},"source":["### 作業目的: 熟練Pytorch Dataset與DataLoader進行資料讀取\n","\n","本此作業主要會使用[IMDB](http://ai.stanford.edu/~amaas/data/sentiment/)資料集利用Pytorch的Dataset與DataLoader進行\n","客製化資料讀取。\n","下載後的資料有分成train與test，因為這份作業目的在讀取資料，所以我們取用train部分來進行練習。\n","(請同學先行至IMDB下載資料)"]},{"cell_type":"markdown","metadata":{"id":"kR-2XDR53Ggn"},"source":["### 載入套件"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NSD0BKPD3Ggn","outputId":"d66df6e1-7e9e-4576-e13c-2dff4bdd603d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Import torch and other required modules\n","import glob\n","import torch\n","import re\n","import nltk\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.datasets import load_svmlight_file\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords') #下載stopwords\n","nltk.download('punkt') #下載word_tokenize需要的corpus"]},{"cell_type":"markdown","metadata":{"id":"P_uUsDAR3Ggs"},"source":["### 探索資料與資料前處理\n","在train資料中，有分成pos(positive)與neg(negative)，分別為正評價與負評價，此評價即為label。"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"oeoqU1O63Ggs","outputId":"8ffbacc8-65ee-4f5d-e4bc-a610322f699e"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab length before removing stopwords: 89527\n","vocab length after removing stopwords: 89356\n"]}],"source":["# 讀取字典，這份字典為review內所有出現的字詞\n","with open('../data/imdb.vocab', 'r') as f:\n","    vocab = f.read()\n","    \n","vocab = vocab.split('\\n')\n","\n","# 以nltk stopwords移除贅字，過多的贅字無法提供有用的訊息，也可能影響模型的訓練\n","print(f\"vocab length before removing stopwords: {len(vocab)}\")\n","vocab = list(set(vocab).difference(set(stopwords.words('english')))) # difference 效果等同於 set1-set2\n","print(f\"vocab length after removing stopwords: {len(vocab)}\")\n","\n","# 將字典轉換成dictionary\n","vocab_dic = dict(zip(vocab, range(len(vocab))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMtQY5Eq3Ggv","outputId":"ee0315a5-277e-45f6-e164-21c5346d8ff3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('./aclImdb/train/pos/4715_9.txt', 1), ('./aclImdb/train/pos/12390_8.txt', 1)]\n","Total reviews: 25000\n"]}],"source":["# 將資料打包成(x, y)配對，其中x為review的檔案路徑，y為正評(1)或負評(0)\n","# 這裡將x以檔案路徑代表的原因是讓同學練習不一次將資料全讀取進來，若電腦記憶體夠大(所有資料檔案沒有很大)\n","# 可以將資料全一次讀取，可以減少在訓練時I/O時間，增加訓練速度\n","\n","###<your code>###\n","print(review_pairs[:2])\n","print(f\"Total reviews: {len(review_pairs)}\")"]},{"cell_type":"markdown","metadata":{"id":"kzt0HH7f3Ggy"},"source":["### 建立Dataset與DataLoader讀取資料\n","這裡我們會需要兩個helper functions，其中一個是讀取資料與清洗資料的函式(load_review)，另外一個是生成詞向量BoW的函式\n","(generate_bow)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K75Uoit_3Ggy"},"outputs":[],"source":["def load_review(review_path):\n","    \n","    ###<your code>###\n","        \n","    #移除non-alphabet符號、贅字與tokenize\n","    ###<your code>###\n","    \n","    return review"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpLFc_kV3Gg1"},"outputs":[],"source":["def generate_bow(review, vocab_dic):\n","    bag_vector = np.zeros(len(vocab_dic))\n","    for word in review:\n","        if vocab_dic.get(word):\n","            bag_vector[vocab_dic.get(word)] += 1\n","            \n","    return bag_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpRZOSzS3Gg3"},"outputs":[],"source":["class dataset(Dataset):\n","    '''custom dataset to load reviews and labels\n","    Parameters\n","    ----------\n","    data_pairs: list\n","        directory of all review-label pairs\n","    vocab: list\n","        list of vocabularies\n","    '''\n","    def __init__(self, data_dirs, vocab):\n","        ###<your code>###\n","\n","    def __len__(self):\n","        ###<your code>###\n","\n","    def __getitem__(self, idx):\n","        ###<your code>###\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPFVLTzy3Gg6","outputId":"bdf581ea-f6de-4534-b5d6-8a9d6cb92e26"},"outputs":[{"data":{"text/plain":["(array([0., 0., 0., ..., 0., 0., 0.]), 1)"]},"execution_count":57,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# 建立客製化dataset\n","###<your code>###\n","custom_dst[10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuvhF5cZ3Gg9","outputId":"12b11c35-0a11-40f3-d523-50120a3c638c"},"outputs":[{"data":{"text/plain":["[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.],\n","         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64),\n"," tensor([0, 0, 1, 0])]"]},"execution_count":59,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# 建立dataloader\n","###<your code>###\n","next(iter(custom_dataloader))"]}],"metadata":{"colab":{"name":"以Pytorch進行基礎資料讀取_作業.ipynb","provenance":[]},"kernelspec":{"display_name":"py310","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
